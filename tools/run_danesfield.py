#!/usr/bin/env python

"""
Run the Danesfield processing pipeline on an AOI from start to finish.
"""

import argparse
import datetime
import logging
import os
import sys

# import other tools
import generate_dsm
import fit_dtm


def create_working_dir(working_dir):
    """
    Create working directory for running algorithms
    All files generated by the system are written to this directory.
    """
    if not working_dir:
        date_str = str(datetime.datetime.now().timestamp())
        working_dir = 'danesfield-' + date_str.split('.')[0]
    if not os.path.isdir(working_dir):
        os.mkdir(working_dir)
    return working_dir


# Note: here are the AOI boundaries for the current AOIs
# D1: 747285 747908 4407065 4407640
# D2: 749352 750082 4407021 4407863
# D3: 477268 478256 3637333 3638307
# D4: 435532 436917 3354107 3355520

def main(args):
    # Configure argument parser
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        '--image-dir',
        type=str,
        required=True,
        help='Imagery source directory')
    parser.add_argument(
        '--working-dir',
        type=str,
        required=False,
        help='A working directory in which to write output files')
    parser.add_argument(
        '--aoi-name',
        type=str,
        required=True,
        help='The name of this AOI, a prefix to output files')
    parser.add_argument(
        "--aoi",
        nargs=4,
        type=float,
        required=True,
        action="store",
        help="Area of Interest (AOI) bounds: minX, maxX, minY, maxY. "
             "Coordinates are specified in UTM "
             "in the zone of the source imagery")
    parser.add_argument(
        "--gsd",
        type=float,
        default=0.25,
        required=False,
        help="Ground sample distance of output imagery "
             "in meters per pixel (default is 0.25)")

    # Parse arguments
    args = parser.parse_args(args)

    # Create working directory
    working_dir = create_working_dir(args.working_dir)

    #############################################
    # Run P3D point cloud generation
    #############################################

    # TODO implement running P3D from Docker
    p3d_file = os.path.join(working_dir, args.aoi_name + "_P3D.bpf")

    #############################################
    # Render DSM from P3D point cloud
    #############################################

    dsm_file = os.path.join(working_dir, args.aoi_name + '_P3D_DSM.tif')
    cmd_args = [dsm_file, '-s', p3d_file, '--bounds']
    cmd_args += list(map(str, args.aoi))
    cmd_args += ['--gsd', str(args.gsd)]
    logging.info("---- Running generate_dsm.py ----")
    logging.debug(cmd_args)
    generate_dsm.main(cmd_args)

    #############################################
    # Fit DTM to the DSM
    #############################################

    dtm_file = os.path.join(working_dir, args.aoi_name + '_DTM.tif')
    cmd_args = [dsm_file, dtm_file]
    logging.info("---- Running fit_dtm.py ----")
    logging.debug(cmd_args)
    fit_dtm.main(cmd_args)

    #############################################
    # Orthorectify images
    #############################################

    # For each source image (PAN and MSI) call orthorectify.py
    # needs to use the DSM, DTM from above and Raytheon RPC file,
    # which is a by-product of P3D.
    #
    # Note: we may eventually select a subset of input images
    # on which to run this and the following steps

    #############################################
    # Pansharpen images
    #############################################

    # Call gdal_pansharpen.py (from GDAL, not Danesfield) like this:
    #    gdal_pansharpen.py PAN_image MSI_image output_image
    # on each of the pairs of matching PAN and MSI orthorectified
    # images from the step above

    #############################################
    # Convert to 8-bit RGB
    #############################################

    # call msi_to_rgb.py on each of the previous Pansharpened images
    # with the '-b' flag to make byte images

    #############################################
    # Segment by Height and Vegetation
    #############################################

    # Call segment_by_height.py using the DSM, DTM, and *one* of the
    # pansharpened images above.  We've been manually picking the most
    # nadir one.  We could do that here or generalize the code to average
    # or otherwise combine the NDVI map from multiple images.
    # the output here has the suffix _threshold_CLS.tif.

    #############################################
    # UNet Semantic Segmentation
    #############################################

    # Collaborate with Chengjiang Long on what to run here

    #############################################
    # Material Segmentation
    #############################################

    # Collaborate with Matt Purri on what to run here

    #############################################
    # PointNet Geon Extraction
    #############################################

    # Collaborate with Xu Zhang (at Columbia) on what to run here

    #############################################
    # Roof Geon Extraction
    #############################################

    # Collaborate with Zhixin Li (and others at Purdue) on what to run here
    # David Stoup is helping with conda packaging

    #############################################
    # Texture Mapping
    #############################################

    # Collaborate with Bastien Jacquet on what to run here
    # Dan Lipsa is helping with conda packaging


if __name__ == '__main__':
    loglevel = os.environ.get('LOGLEVEL', 'INFO').upper()
    logging.basicConfig(level=loglevel)

    main(sys.argv[1:])
